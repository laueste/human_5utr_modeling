{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from Bio.Seq import Seq\n",
    "from Bio import motifs\n",
    "import random\n",
    "\n",
    "import keras\n",
    "np.random.seed(1337)\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "### Parameters for plotting model results ###\n",
    "pd.set_option(\"display.max_colwidth\",100)\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "plt.rcParams['font.weight'] = 'normal'\n",
    "plt.rcParams['axes.labelweight'] = 'normal'\n",
    "plt.rcParams['axes.labelpad'] = 5\n",
    "plt.rcParams['axes.linewidth']= 2\n",
    "plt.rcParams['xtick.labelsize']= 14\n",
    "plt.rcParams['ytick.labelsize']= 14\n",
    "plt.rcParams['xtick.major.size'] = 6\n",
    "plt.rcParams['ytick.major.size'] = 6\n",
    "plt.rcParams['xtick.minor.size'] = 3\n",
    "plt.rcParams['ytick.minor.size'] = 3\n",
    "plt.rcParams['xtick.minor.width'] = 1\n",
    "plt.rcParams['ytick.minor.width'] = 1\n",
    "plt.rcParams['xtick.major.width'] = 2\n",
    "plt.rcParams['ytick.major.width'] = 2\n",
    "plt.rcParams['xtick.color'] = 'black'\n",
    "plt.rcParams['ytick.color'] = 'black'\n",
    "plt.rcParams['axes.labelcolor'] = 'black'\n",
    "plt.rcParams['axes.edgecolor'] = 'black'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data(df, model, test_seq, obs_col, output_col='pred'):\n",
    "    '''Predict mean ribosome load using model and test set UTRs'''\n",
    "    \n",
    "    # Scale the test set mean ribosome load\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    scaler.fit(df[obs_col].values.reshape(-1,1))   #LAE: .values added, pd deprecation\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(test_seq).reshape(-1)\n",
    "    \n",
    "    # Inverse scaled predicted mean ribosome load and return in a column labeled 'pred'\n",
    "    df.loc[:,output_col] = scaler.inverse_transform(predictions)\n",
    "    return df\n",
    "\n",
    "\n",
    "def one_hot_encode(df, col='utr', seq_len=50):\n",
    "    # Dictionary returning one-hot encoding of nucleotides. \n",
    "    nuc_d = {'a':[1,0,0,0],'c':[0,1,0,0],'g':[0,0,1,0],'t':[0,0,0,1], 'n':[0,0,0,0]}\n",
    "    \n",
    "    # Creat empty matrix.\n",
    "    vectors=np.empty([len(df),seq_len,4])\n",
    "    \n",
    "    # Iterate through UTRs and one-hot encode\n",
    "    for i,seq in enumerate(df[col].str[:seq_len]): \n",
    "        seq = seq.lower()\n",
    "        a = np.array([nuc_d[x] for x in seq])\n",
    "        vectors[i] = a\n",
    "    return vectors\n",
    "\n",
    "\n",
    "def r2(x,y):\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "    return r_value**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/usr/local/lib/python2.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "#df = pd.read_pickle('../data/egfp_unmod_1.pkl')  #LAE: do not have this pickle file...?\n",
    "df = pd.read_csv('../data/egfp_unmod_1.csv')\n",
    "df.sort_values('total_reads', inplace=True, ascending=False)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df = df.iloc[:280000]\n",
    "\n",
    "# The training set has 260k UTRs and the test set has 20k UTRs.\n",
    "e_test = df.iloc[:20000]\n",
    "e_train = df.iloc[20000:]\n",
    "\n",
    "# One-hot encode both training and test UTRs\n",
    "seq_e_train = one_hot_encode(e_train,seq_len=50)\n",
    "seq_e_test = one_hot_encode(e_test, seq_len=50)\n",
    "\n",
    "# Scale the training mean ribosome load values\n",
    "# LAE: added .values before reshape due to pandas naming deprecation\n",
    "e_train.loc[:,'scaled_rl'] = preprocessing.StandardScaler().fit_transform(e_train.loc[:,'rl'].values.reshape(-1,1))\n",
    "\n",
    "label_e_train = e_train['scaled_rl']\n",
    "label_e_test = e_test['rl']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x, y, border_mode='same', inp_len=50, nodes=40, layers=3, filter_len=8, nbr_filters=120,\n",
    "                dilation1=3, dilation2=1, dilation3=1, \n",
    "                dropout1=0, dropout2=0, dropout3=0, nb_epoch=3):\n",
    "    ''' Build model archicture and fit.'''\n",
    "    model = Sequential()\n",
    "    if layers >= 1:\n",
    "        model.add(Conv1D(activation=\"relu\", input_shape=(inp_len, 4), dilation_rate=dilation1,\n",
    "                         padding=border_mode, filters=nbr_filters, kernel_size=filter_len))\n",
    "    if layers >= 2:\n",
    "        model.add(Conv1D(activation=\"relu\", input_shape=(inp_len, 1), dilation_rate=dilation2,\n",
    "                         padding=border_mode, filters=nbr_filters, kernel_size=filter_len))\n",
    "        model.add(Dropout(dropout1))\n",
    "    if layers >= 3:\n",
    "        model.add(Conv1D(activation=\"relu\", input_shape=(inp_len, 1), dilation_rate=dilation3, \n",
    "                         padding=border_mode, filters=nbr_filters, kernel_size=filter_len))\n",
    "        model.add(Dropout(dropout2))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(nodes))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout3))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('linear'))\n",
    "\n",
    "    #compile the model\n",
    "    adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "\n",
    "    model.fit(x, y, batch_size=128, epochs=nb_epoch, verbose=1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_pickle('../data/egfp_unmod_1.pkl')  #LAE: do not have this pickle file...?\n",
    "df = pd.read_csv('../data/egfp_unmod_1.csv')\n",
    "df.sort_values('total_reads', inplace=True, ascending=False)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df = df.iloc[:280000]\n",
    "\n",
    "# The training set has 260k UTRs and the test set has 20k UTRs.\n",
    "e_test = df.iloc[:20000]\n",
    "e_train = df.iloc[20000:]\n",
    "\n",
    "# One-hot encode both training and test UTRs\n",
    "seq_e_train = one_hot_encode(e_train,seq_len=50)\n",
    "seq_e_test = one_hot_encode(e_test, seq_len=50)\n",
    "\n",
    "# Scale the training mean ribosome load values\n",
    "# LAE: added .values before reshape due to pandas naming deprecation\n",
    "e_train.loc[:,'scaled_rl'] = preprocessing.StandardScaler().fit_transform(e_train.loc[:,'rl'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "260000/260000 [==============================] - 164s 632us/step - loss: 0.3056\n",
      "Epoch 2/3\n",
      "260000/260000 [==============================] - 165s 635us/step - loss: 0.1764\n",
      "Epoch 3/3\n",
      "260000/260000 [==============================] - 183s 702us/step - loss: 0.1635\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1337)\n",
    "model = train_model(seq_e_train, e_train['scaled_rl'], nb_epoch=3, border_mode='same',\n",
    "                    inp_len=50, nodes=40, layers=3, nbr_filters=120, filter_len=8,\n",
    "                    dilation1=4, dilation2=1, dilation3=1,\n",
    "                    dropout1=0, dropout2=0,dropout3=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r-squared =  0.9208056621490419\n"
     ]
    }
   ],
   "source": [
    "e_test = test_data(df=e_test, model=model, obs_col='rl',test_seq=seq_e_test)\n",
    "r = r2(e_test['rl'], e_test['pred'])\n",
    "print 'r-squared = ', r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "260000/260000 [==============================] - 183s 705us/step - loss: 0.3519\n",
      "Epoch 2/3\n",
      "260000/260000 [==============================] - 184s 706us/step - loss: 0.1799\n",
      "Epoch 3/3\n",
      "260000/260000 [==============================] - 183s 704us/step - loss: 0.1639\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1337)\n",
    "model2 = train_model(seq_e_train, e_train['scaled_rl'], nb_epoch=3, border_mode='same',\n",
    "                    inp_len=50, nodes=40, layers=3, nbr_filters=120, filter_len=8,\n",
    "                    dilation1=7, dilation2=1, dilation3=1,\n",
    "                    dropout1=0, dropout2=0,dropout3=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r-squared =  0.9200812403300191\n"
     ]
    }
   ],
   "source": [
    "e_test = test_data(df=e_test, model=model2, obs_col='rl',test_seq=seq_e_test)\n",
    "r = r2(e_test['rl'], e_test['pred'])\n",
    "print 'r-squared = ', r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "# name = 'dilated_CNN_d4_l3.hdf5'\n",
    "# model.save('./saved_models/'+name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Model Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "model = keras.models.load_model('./saved_models/'+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atg = e_test[e_test['utr'].apply(lambda x: 'ATG' in x)]\n",
    "n_atg = e_test[e_test['utr'].apply(lambda x: 'ATG' not in x)]\n",
    "print \"Number of utrs with ATG:\", len(atg)\n",
    "print \"Number of utrs without ATG:\", len(n_atg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = (0.3, 0.45, 0.69)\n",
    "c2 = 'r'\n",
    "g = sns.JointGrid(x='rl', y=\"pred\", data=atg, space=0, xlim=(1,10), ylim=(0,10), ratio=6, size=7)\n",
    "g.plot_joint(plt.scatter,s=20, color=c1, linewidth=0.2, alpha='0.1', edgecolor='white')\n",
    "f = g.fig\n",
    "ax = f.gca()\n",
    "ax.set_yticks(np.arange(0,9.01, 1));\n",
    "ax.set_yticklabels(range(10),size=20);\n",
    "ax.set_xticks(np.arange(1,10.01, 1));\n",
    "ax.set_xticklabels(range(1,11),size=20);\n",
    "ax.set_ylim(0,9)\n",
    "ax.set_xlim(1,10)\n",
    "g.plot_marginals(sns.kdeplot,shade=c1, **{'linewidth':2, 'color':c1})\n",
    "g.set_axis_labels('Observed MRL', 'Predicted MRL', **{'size':22});\n",
    "\n",
    "g.x = n_atg['rl'].values\n",
    "g.y = n_atg['pred'].values\n",
    "g.plot_joint(plt.scatter, s=20, linewidth=0.2, alpha='0.2', color=c2, edgecolor='white')\n",
    "g.plot_marginals(sns.kdeplot, shade=c2, **{'linewidth':2, 'color':c2})\n",
    "f = g.fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
